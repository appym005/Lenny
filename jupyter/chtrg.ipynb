{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  [\"'s\", ',', 'a', 'anyone', 'are', 'awesome', 'be', 'bye', 'can', 'chatting', 'could', 'day', 'do', 'fact', 'for', 'fsdh', 'good', 'goodbye', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hola', 'how', 'is', 'later', 'lookup', 'me', 'next', 'nice', 'offered', 'provide', 'random', 'see', 'sjdfhk', 'support', 'surprise', 'tell', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'wa', 'what', 'when', 'where', 'who', 'you']\n",
      "Classes:  ['answer', 'goodbye', 'greeting', 'noanswer', 'options', 'surprise', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "print(\"Words: \",words)\n",
    "print(\"Classes: \",classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    print(\"Sentence words: \",sentence_words)\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    print(\"Going to clean_up_sentence\")\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    print(\"Back to bow\")\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    print(\"Bag: \", np.array(bag))\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    print(\"Going to bow\")\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    print(\"Back to predict class\")\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    print(\"Res: \",res)\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(\"Results :\", results)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    print(\"Return list: \",return_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    print(\"Result: \",result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(msg):\n",
    "    print(\"Going to predict_class\")\n",
    "    ints = predict_class(msg, model)\n",
    "    print(\"Ints: \", ints)\n",
    "    print(\"Back to chatbot response\")\n",
    "    print(\"Going to getResponse\")\n",
    "    res = getResponse(ints, intents)\n",
    "    print(\"Back to chatbot_response\")\n",
    "    print(\"Res: \",res)\n",
    "    if ints[0]['intent'] == 'answer':\n",
    "        response = res + \" \" + search(msg)\n",
    "        return response\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(msg):\n",
    "    return \"looking up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to predict_class\n",
      "Going to bow\n",
      "Going to clean_up_sentence\n",
      "Sentence words:  ['who', 'wa', 'akbar', '?']\n",
      "Back to bow\n",
      "Bag:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "Back to predict class\n",
      "Res:  [9.99987006e-01 3.44296822e-08 6.25119938e-08 1.17097716e-05\n",
      " 1.03634102e-06 1.05302284e-07 1.48935930e-08]\n",
      "Results : [[0, 0.999987]]\n",
      "Return list:  [{'intent': 'answer', 'probability': '0.999987'}]\n",
      "Ints:  [{'intent': 'answer', 'probability': '0.999987'}]\n",
      "Back to chatbot response\n",
      "Going to getResponse\n",
      "Result:  Here's what I found:\n",
      "Back to chatbot_response\n",
      "Res:  Here's what I found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here's what I found: looking up\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"Who was akbar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi there', 'How are you', 'Is anyone there?', 'Hey', 'Hola', 'Hello', 'Good day'], 'responses': ['Hello, thanks for asking', 'Good to see you again', 'Hi there, how can I help?'], 'context': ['']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time'], 'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'], 'context': ['']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure'], 'context': ['']}, {'tag': 'noanswer', 'patterns': [' ', '', 'fsdh sjdfhk'], 'responses': [\"Sorry, can't understand you\", 'Please give me more info', 'Not sure I understand'], 'context': ['']}, {'tag': 'options', 'patterns': ['How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered'], 'responses': ['I can lookup answers to your questions on the internet.'], 'context': ['']}, {'tag': 'surprise', 'patterns': ['surprise me', 'tell me a random fact', 'random', 'surprise'], 'responses': [\"Here's one:\"], 'context': ['']}, {'tag': 'answer', 'patterns': ['who', 'What', 'where', 'how', 'when', 'lookup', 'is', ' what is', 'where was', 'where is'], 'responses': [\"Here's what I found:\"], 'context': ['question']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
